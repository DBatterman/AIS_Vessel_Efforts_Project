{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b431f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Fix a random seed so the data can be reproduced\n",
    "np.random.seed(24)\n",
    "\n",
    "# Upload and read the csv files\n",
    "ais_df = pd.read_csv(\"ml_data_daily_2018.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa959ae4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fishing</th>\n",
       "      <th>TugTow</th>\n",
       "      <th>Recreational</th>\n",
       "      <th>Passenger</th>\n",
       "      <th>Cargo</th>\n",
       "      <th>Tanker</th>\n",
       "      <th>Other</th>\n",
       "      <th>Unavailable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018/01/01</th>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>145</td>\n",
       "      <td>44</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/01/02</th>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>119</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/01/03</th>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>106</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/01/04</th>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>103</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/01/05</th>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>107</td>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fishing  TugTow  Recreational  Passenger  Cargo  Tanker  Other  \\\n",
       "2018/01/01        9      37           145         44     27      13     12   \n",
       "2018/01/02       13      45           119         41     27      14     19   \n",
       "2018/01/03       13      44           106         40     36      14     20   \n",
       "2018/01/04       15      44           103         45     30      10     15   \n",
       "2018/01/05       10      45           107         41     26      13     21   \n",
       "\n",
       "            Unavailable  \n",
       "2018/01/01            7  \n",
       "2018/01/02           10  \n",
       "2018/01/03           11  \n",
       "2018/01/04           12  \n",
       "2018/01/05           10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at our data\n",
    "ais_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1455e23e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fishing</th>\n",
       "      <th>TugTow</th>\n",
       "      <th>Recreational</th>\n",
       "      <th>Passenger</th>\n",
       "      <th>Cargo</th>\n",
       "      <th>Tanker</th>\n",
       "      <th>Other</th>\n",
       "      <th>Unavailable</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018/01/01</th>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>145</td>\n",
       "      <td>44</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/01/02</th>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>119</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/01/03</th>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>106</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/01/04</th>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>103</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/01/05</th>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>107</td>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fishing  TugTow  Recreational  Passenger  Cargo  Tanker  Other  \\\n",
       "2018/01/01        9      37           145         44     27      13     12   \n",
       "2018/01/02       13      45           119         41     27      14     19   \n",
       "2018/01/03       13      44           106         40     36      14     20   \n",
       "2018/01/04       15      44           103         45     30      10     15   \n",
       "2018/01/05       10      45           107         41     26      13     21   \n",
       "\n",
       "            Unavailable  Total  \n",
       "2018/01/01            7    294  \n",
       "2018/01/02           10    288  \n",
       "2018/01/03           11    284  \n",
       "2018/01/04           12    274  \n",
       "2018/01/05           10    273  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a total column for our data\n",
    "ais_df['Total']= ais_df.sum(axis=1)\n",
    "ais_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ba0f154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 365 entries, 2018/01/01 to 2018/12/31\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   Fishing       365 non-null    int64\n",
      " 1   TugTow        365 non-null    int64\n",
      " 2   Recreational  365 non-null    int64\n",
      " 3   Passenger     365 non-null    int64\n",
      " 4   Cargo         365 non-null    int64\n",
      " 5   Tanker        365 non-null    int64\n",
      " 6   Other         365 non-null    int64\n",
      " 7   Unavailable   365 non-null    int64\n",
      " 8   Total         365 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 28.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# And then check the type\n",
    "ais_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17356cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nine DataFrames, each with the Date and one unique column:\n",
    "\n",
    "# Fishing\n",
    "ais_fishing_df = ais_df.loc[:, ['Fishing']]\n",
    "\n",
    "# TugTow\n",
    "ais_tugtow_df = ais_df.loc[:, ['TugTow']]\n",
    "\n",
    "# Recreational\n",
    "ais_recreational_df = ais_df.loc[:, ['Recreational']]\n",
    "\n",
    "# Passenger\n",
    "ais_passenger_df = ais_df.loc[:, ['Passenger']]\n",
    "\n",
    "# Cargo\n",
    "ais_cargo_df = ais_df.loc[:, ['Cargo']]\n",
    "\n",
    "# Tanker\n",
    "ais_tanker_df = ais_df.loc[:, ['Tanker']]\n",
    "\n",
    "# Other\n",
    "ais_other_df = ais_df.loc[:, ['Other']]\n",
    "\n",
    "# Unavailable\n",
    "ais_unavailable_df = ais_df.loc[:, ['Unavailable']]\n",
    "\n",
    "# Total\n",
    "ais_total_df = ais_df.loc[:, ['Total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c69479f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018/01/01</th>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/01/02</th>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/01/03</th>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/01/04</th>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/01/05</th>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/12/27</th>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/12/28</th>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/12/29</th>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/12/30</th>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/12/31</th>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Total\n",
       "2018/01/01    294\n",
       "2018/01/02    288\n",
       "2018/01/03    284\n",
       "2018/01/04    274\n",
       "2018/01/05    273\n",
       "...           ...\n",
       "2018/12/27    298\n",
       "2018/12/28    298\n",
       "2018/12/29    306\n",
       "2018/12/30    308\n",
       "2018/12/31    297\n",
       "\n",
       "[365 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From here we will be using 'Total' as an example, and repeating the code for the rest of the data\n",
    "\n",
    "# Check the new DataFrame\n",
    "ais_total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19802b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here, the code is heavily inspired by the code found on this site:\n",
    "# https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6bb4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM (x):\n",
    "    # Convert the DataFrame into an array, and change the type to floats for the Neural Network\n",
    "    data = x.values\n",
    "    data = data.astype('float32')\n",
    "    \n",
    "    # Normalize the data by using a scaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data = scaler.fit_transform(data)\n",
    "    \n",
    "    # Split our data into training and testing using slicing, and check the length\n",
    "\n",
    "    # Determin the length of what our split will be\n",
    "    data_split = int(len(data) * 0.75)\n",
    "    \n",
    "    #Slice the data and print the results\n",
    "    train, test = data[:data_split], data[data_split:]\n",
    "    \n",
    "    # Convert an array of values into a dataset matrix\n",
    "    def create_dataset(dataset, look_back=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-look_back-1):\n",
    "            a = dataset[i:(i+look_back), 0]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + look_back, 0])\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "    \n",
    "    # Reshape the values into X=t and Y=t+1\n",
    "    look_back = 1\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    \n",
    "    # Reshape the data to incorperate into the LSTM\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    \n",
    "    # create and fit the LSTM network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, activation='relu', input_shape=(1, look_back)))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae', 'mape'])\n",
    "    es = [EarlyStopping(monitor='loss', patience=15)]\n",
    "    fit_model = model.fit(trainX, trainY, epochs=100, validation_split=0.3, batch_size=1, verbose=2, callbacks=[es])\n",
    "    \n",
    "    # Make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    \n",
    "    # Invert predictions\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "    \n",
    "    # Calculate root mean squared error\n",
    "    trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "    testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "    # And print the RMSE\n",
    "    show_trainScore = 'Train Score: %.2f RMSE' % (trainScore)\n",
    "    show_testScore = 'Test Score: %.2f RMSE' % (testScore)\n",
    "    \n",
    "    # shift train predictions for plotting\n",
    "    trainPredictPlot = np.empty_like(data)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "    # shift test predictions for plotting\n",
    "    testPredictPlot = np.empty_like(data)\n",
    "    testPredictPlot[:, :] = np.nan\n",
    "    testPredictPlot[len(trainPredict)+(look_back*2)+1:len(data)-1, :] = testPredict\n",
    "    # plot baseline and predictions\n",
    "    plt.plot(scaler.inverse_transform(data))\n",
    "    plt.plot(trainPredictPlot)\n",
    "    plt.plot(testPredictPlot)\n",
    "    graph = plt.show()\n",
    "  \n",
    "    return fit_model, show_trainScore, show_testScore, graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b50468f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LSTM() got an unexpected keyword argument 'input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38536/708342808.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Check the function with 'total'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mais_total_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38536/2128155759.py\u001b[0m in \u001b[0;36mLSTM\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# create and fit the LSTM network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: LSTM() got an unexpected keyword argument 'input_shape'"
     ]
    }
   ],
   "source": [
    "# Check the function with 'total'\n",
    "LSTM(ais_total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17608de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame into an array, and change the type to floats for the Neural Network\n",
    "\n",
    "total = ais_total_df.values\n",
    "total = total.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df82cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data by using a scaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "total = scaler.fit_transform(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data into training and testing using slicing, and check the length\n",
    "\n",
    "# Determin the length of what our split will be\n",
    "total_split = int(len(total) * 0.75)\n",
    "\n",
    "#Slice the data and print the results\n",
    "train, test = total[:total_split], total[total_split:]\n",
    "print(len(train), len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a5382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the values into X=t and Y=t+1\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28928b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to incorperate into the LSTM\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c4fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "\n",
    "# Create the initial layer\n",
    "model.add(LSTM(4, activation='relu', input_shape=(1, look_back)))\n",
    "\n",
    "# Create the second layer\n",
    "model.add(Dense(2))\n",
    "\n",
    "# Create the third layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2528d2ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca304de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae', 'mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc780ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating callbacks to load the model for a future time\n",
    "es = [EarlyStopping(monitor='loss', patience=15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ca600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fit_model = model.fit(trainX, trainY, epochs=100, validation_split=0.3, batch_size=1, verbose=2, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb6bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the keys of the model\n",
    "fit_model.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb5b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the loss\n",
    "plt.plot(fit_model.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the MSE, which should be equal to the loss\n",
    "plt.plot(fit_model.history[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd52cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the mae\n",
    "plt.plot(fit_model.history[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50133752",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the mape\n",
    "plt.plot(fit_model.history[\"mape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e15162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the val_loss\n",
    "plt.plot(fit_model.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f39a4f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the val_mse\n",
    "plt.plot(fit_model.history[\"val_mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b2c72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the val_mae\n",
    "plt.plot(fit_model.history[\"val_mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee75c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the val_mape\n",
    "plt.plot(fit_model.history[\"val_mape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b16dad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d754fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555906d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a578b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(total)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(total)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(total)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(total))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb938d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
