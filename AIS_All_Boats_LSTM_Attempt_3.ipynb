{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b431f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Fix a random seed so the data can be reproduced\n",
    "np.random.seed(24)\n",
    "\n",
    "# Upload and read the csv files\n",
    "ais_df = pd.read_csv(\"full_ais_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa959ae4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fishing</th>\n",
       "      <th>TugTow</th>\n",
       "      <th>Recreational</th>\n",
       "      <th>Passenger</th>\n",
       "      <th>Cargo</th>\n",
       "      <th>Tanker</th>\n",
       "      <th>Other</th>\n",
       "      <th>Unavailable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>9.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>13.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>13.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>15.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fishing  TugTow  Recreational  Passenger  Cargo  Tanker  Other  \\\n",
       "index                                                                        \n",
       "2018-01-01      9.0    37.0         145.0       44.0   27.0    13.0   12.0   \n",
       "2018-01-02     13.0    45.0         119.0       41.0   27.0    14.0   19.0   \n",
       "2018-01-03     13.0    44.0         106.0       40.0   36.0    14.0   20.0   \n",
       "2018-01-04     15.0    44.0         103.0       45.0   30.0    10.0   15.0   \n",
       "2018-01-05     10.0    45.0         107.0       41.0   26.0    13.0   21.0   \n",
       "\n",
       "            Unavailable  \n",
       "index                    \n",
       "2018-01-01          7.0  \n",
       "2018-01-02         10.0  \n",
       "2018-01-03         11.0  \n",
       "2018-01-04         12.0  \n",
       "2018-01-05         10.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at our data\n",
    "ais_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1455e23e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fishing</th>\n",
       "      <th>TugTow</th>\n",
       "      <th>Recreational</th>\n",
       "      <th>Passenger</th>\n",
       "      <th>Cargo</th>\n",
       "      <th>Tanker</th>\n",
       "      <th>Other</th>\n",
       "      <th>Unavailable</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>9.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>13.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>13.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>15.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fishing  TugTow  Recreational  Passenger  Cargo  Tanker  Other  \\\n",
       "index                                                                        \n",
       "2018-01-01      9.0    37.0         145.0       44.0   27.0    13.0   12.0   \n",
       "2018-01-02     13.0    45.0         119.0       41.0   27.0    14.0   19.0   \n",
       "2018-01-03     13.0    44.0         106.0       40.0   36.0    14.0   20.0   \n",
       "2018-01-04     15.0    44.0         103.0       45.0   30.0    10.0   15.0   \n",
       "2018-01-05     10.0    45.0         107.0       41.0   26.0    13.0   21.0   \n",
       "\n",
       "            Unavailable  Total  \n",
       "index                           \n",
       "2018-01-01          7.0  294.0  \n",
       "2018-01-02         10.0  288.0  \n",
       "2018-01-03         11.0  284.0  \n",
       "2018-01-04         12.0  274.0  \n",
       "2018-01-05         10.0  273.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a total column for our data\n",
    "ais_df['Total']= ais_df.sum(axis=1)\n",
    "ais_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And then check DataFrame for type and any nans\n",
    "ais_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17356cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nine DataFrames, one for each type of boat and the total:\n",
    "\n",
    "# Fishing\n",
    "ais_fishing_df = ais_df.loc[:, ['Fishing']]\n",
    "\n",
    "# TugTow\n",
    "ais_tugtow_df = ais_df.loc[:, ['TugTow']]\n",
    "\n",
    "# Recreational\n",
    "ais_recreational_df = ais_df.loc[:, ['Recreational']]\n",
    "\n",
    "# Passenger\n",
    "ais_passenger_df = ais_df.loc[:, ['Passenger']]\n",
    "\n",
    "# Cargo\n",
    "ais_cargo_df = ais_df.loc[:, ['Cargo']]\n",
    "\n",
    "# Tanker\n",
    "ais_tanker_df = ais_df.loc[:, ['Tanker']]\n",
    "\n",
    "# Other\n",
    "ais_other_df = ais_df.loc[:, ['Other']]\n",
    "\n",
    "# Unavailable\n",
    "ais_unavailable_df = ais_df.loc[:, ['Unavailable']]\n",
    "\n",
    "# Total\n",
    "ais_total_df = ais_df.loc[:, ['Total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19802b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here, the code is heavily inspired by the code found on the following sites:\n",
    "# https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "# https://towardsdatascience.com/time-series-forecasting-with-recurrent-neural-networks-74674e289816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to automate making a model for all nine Dataframes\n",
    "def BoatModel (x):\n",
    "    # Convert the DataFrame into an array, and change the type to floats for the Neural Network\n",
    "    data = x.values\n",
    "    data = data.astype('float32')\n",
    "    \n",
    "    # Normalize the data by using a scaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data = scaler.fit_transform(data)\n",
    "    \n",
    "    # Split our data into training and testing using slicing, and check the length\n",
    "\n",
    "    # Determin the length of what our split will be\n",
    "    data_split = int(len(data) * 0.75)\n",
    "    \n",
    "    #Slice the data and print the results\n",
    "    train, test = data[:data_split], data[data_split:]\n",
    "    \n",
    "    # Make a function that creates both X and y values for the data\n",
    "    def create_dataset(dataset, look_back=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-look_back-1):\n",
    "            a = dataset[i:(i+look_back), 0]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + look_back, 0])\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "    \n",
    "    # Define how much time we're looking into the past, \n",
    "    # and split our values into X=t and Y=t+1, where t is that time\n",
    "    look_back = 1\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    \n",
    "    # Reshape the data to incorperate into the LSTM\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    \n",
    "    # Create and fit the LSTM network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, activation='relu', input_shape=(1, look_back)))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae', 'mape'])\n",
    "    es = [EarlyStopping(monitor='loss', patience=15)]\n",
    "    fit_model = model.fit(trainX, trainY, epochs=100, validation_split=0.3, batch_size=1, verbose=2, callbacks=[es])\n",
    "    \n",
    "    # Make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    \n",
    "    # Invert the predictions to graph later\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "    \n",
    "    # Calculate root mean squared error\n",
    "    trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "    testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "    \n",
    "    # And catch the results to print later\n",
    "    show_trainScore = 'Train Score: %.2f RMSE' % (trainScore)\n",
    "    show_testScore = 'Test Score: %.2f RMSE' % (testScore)\n",
    "    \n",
    "    # Shift the train predictions for plotting\n",
    "    trainPredictPlot = np.empty_like(data)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "    \n",
    "    # Shift the test predictions for plotting\n",
    "    testPredictPlot = np.empty_like(data)\n",
    "    testPredictPlot[:, :] = np.nan\n",
    "    testPredictPlot[len(trainPredict)+(look_back*2)+1:len(data)-1, :] = testPredict\n",
    "     \n",
    "   # Create a function for future predictions\n",
    "    \n",
    "    def predict(num_prediction, model):\n",
    "        prediction_list = data[-look_back:]\n",
    "    \n",
    "        for _ in range(num_prediction):\n",
    "            x = prediction_list[-look_back:]\n",
    "            x = x.reshape((1, look_back, 1))\n",
    "            out = model.predict(x)[0][0]\n",
    "            prediction_list = np.append(prediction_list, out)\n",
    "        prediction_list = prediction_list[look_back-1:]\n",
    "        \n",
    "        return prediction_list\n",
    "    \n",
    "    # Predict the next 30 days of data\n",
    "    forecast = predict(30, model)\n",
    "    forecast = forecast.reshape((-1,1))\n",
    "    forecast = scaler.inverse_transform(forecast)\n",
    "    \n",
    "    # Plot the prediction on a graph\n",
    "    \n",
    "    future = len(data) + len(forecast)\n",
    "\n",
    "    futurePlot = np.zeros((future ,1))\n",
    "    futurePlot[:, :] = np.nan\n",
    "    futurePlot[-len(forecast): ] = forecast\n",
    "\n",
    "    \n",
    "     # Plot the root data, train, test, and future outcomes\n",
    "    plt.plot(scaler.inverse_transform(data))\n",
    "    plt.plot(trainPredictPlot)\n",
    "    plt.plot(testPredictPlot)\n",
    "    plt.plot(futurePlot)\n",
    "    graph = plt.show()\n",
    "  \n",
    "    return show_trainScore, show_testScore, graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8037374",
   "metadata": {},
   "source": [
    "### Fishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e90b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoatModel(ais_fishing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad02dfaf",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### TugTow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb938d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoatModel(ais_tugtow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49c9cd1",
   "metadata": {},
   "source": [
    "### Recreational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoatModel(ais_recreational_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1041e",
   "metadata": {},
   "source": [
    "### Passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f9c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoatModel(ais_passenger_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5c842c",
   "metadata": {},
   "source": [
    "### Cargo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a874aeb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BoatModel(ais_cargo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc429a2",
   "metadata": {},
   "source": [
    "### Tanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoatModel(ais_tanker_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14923d2e",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da5f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoatModel(ais_other_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b022b",
   "metadata": {},
   "source": [
    "### Unavailable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f9d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoatModel(ais_unavailable_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257a6d74",
   "metadata": {},
   "source": [
    "### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb3166",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoatModel(ais_total_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
